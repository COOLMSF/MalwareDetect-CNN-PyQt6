import os
import sys

import tensorflow as tf #to use tensorflow
from tensorflow.keras.preprocessing import image  #for data preprocessing in keras
import matplotlib.pyplot as plt #for plotting 
from pyngrok import ngrok #for taking the token to run on local
from PIL import Image #to import images
import numpy as np #to use numpy arrays
from tensorflow import keras #to import keras from tensorflow
from tensorflow.keras.models import load_model  #to load keras model
from tensorflow.keras import preprocessing #for data preprocessing from keras
import time #to calculate the time
from tensorflow.keras.applications.resnet import ResNet101 #to use ResNet101 model
from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten,Dropout,Dense #for keras layers
from tensorflow.keras.models import Sequential, Model #for keras sequential model
# import splitfolders #to split the dataset folders
import sys
import os #to import the operating system
from math import log #to use log from math
import scipy as sp #to use scipy library
from tensorflow.keras.preprocessing.image import ImageDataGenerator #for image generator from keras
import tensorflow.keras #to import keras
from tensorflow.keras.layers import Dense, Dropout, Flatten , Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization #to use batch normalization
# from sklearn import metrics #for importing metrics from sklearn
from tensorflow.keras.applications import VGG16  #to use VGG16 model
# from sklearn.utils import class_weight #to handle imbalanced data

sys.path.append("/home/coolder/data/Learning/AI/DL/MalwareDetect/code")

from Utils.exec2img import Exec2img

#define a function for AlexNet model
class Alexnet():
    model = None
    model_trained = None
    
    def __init__(self):
        #define the model as sequential model
        model = Sequential()
        img_size  = 150

        #layer 1 of the model  ------>  convolutional layer + max-pooling layer
        model.add(Conv2D(filters = 96, kernel_size = (11,11), strides= 4, padding = 'valid', 
                         activation='relu', input_shape=(img_size,img_size,3)))
        model.add(MaxPooling2D(pool_size = (3,3), strides = 2))

        #layer 2 of the model  ------>  convolutional layer + max-pooling layer
        model.add(Conv2D(filters = 256, kernel_size = (5,5), padding = 'same', 
                         activation = 'relu'))
        model.add(MaxPooling2D(pool_size = (3,3), strides = 2))

        #layers 3 to 5  of the model  ------>  convolutional layer + 1 max-pooling layer
        model.add(Conv2D(filters = 384, kernel_size = (3,3), padding = 'same', 
                         activation = 'relu'))
        model.add(Conv2D(filters = 384, kernel_size = (3,3), padding = 'same', 
                         activation = 'relu'))
        model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = 'same', 
                         activation = 'relu'))
        model.add(MaxPooling2D(pool_size = (3,3), strides = 2))

        #layers 6 to 8 of the model  ------> two fully connected hidden layers and one fully connected output layer

        #make a flatten layer
        model.add(Flatten())
  
        #set the output layer activation as a softmax 
        model.add(Dense(25, activation = 'softmax'))

        #compile the model using adam optimizer
        model.compile(loss = 'categorical_crossentropy',
                      optimizer = 'adam',
                      metrics = ['accuracy'])

        self.model = model
    
    
    
    def load_specify_model(self, model_filename):
        self.model_trained = tf.keras.models.load_model(model_filename, )
    
    def eval(self):
        pass
    
    def predict(self, source_file :str):
        # if not source_file.endswith('.exe'):
        #     print("Invalid file to predict")
            
        program_name = source_file.split('.')[0]
        dest_file = program_name + ".png"
        exec = Exec2img()
        exec.exec2img(source_file, dest_file)
        z=plt.imread(dest_file)
        plt.imshow(z)

        img = tf.keras.utils.load_img(dest_file, target_size=(150, 150))
        x = tf.keras.utils.img_to_array(img)
        x = np.expand_dims(x, axis=0) 
        classes = self.model.predict(x)
        classes = np.argmax(classes)

        #set the images labels
        label = ['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.P', 'C2LOP.gen!g', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A']
        return(label[classes])
    
    #to visualize some images from the data
    def plots(self, ims, figsize=(20,30), rows=10, interp=False, titles=None):
    
        img_size = 150
        if type(ims[0]) is np.ndarray:
            ims = np.array(ims).astype(np.uint8)
            if (ims.shape[-1] != 3):
                ims = ims.transpose((0,2,3,1))
        f = plt.figure(figsize=figsize)
        cols = 10 # len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    
        #to show images 
        for i in range(0,50):
            sp = f.add_subplot(rows, cols, i+1)
            sp.axis('Off')
            if titles is not None:
                train = ImageDataGenerator().flow_from_directory(directory='train', target_size=(img_size,img_size), batch_size=10000)
                sp.set_title(list(train.class_indices.keys())[np.argmax(titles[i])], fontsize=16)
            plt.imshow(ims[i], interpolation=None if interp else 'none')
            
        plt.show()
            
    def train(self, data_path, save_path):
        
        # splitfolders.ratio('/content/malimg_paper_dataset_imgs', output="/content/", seed=1337,
        
        os.chdir(data_path)
        
        #set the image size to 150
        img_size = 150
        #set the training data
        # train = ImageDataGenerator().flow_from_directory(directory='train', target_size=(img_size,img_size), batch_size=10000)
        train = ImageDataGenerator().flow_from_directory(directory='train', target_size=(img_size,img_size), batch_size=10000)
        #set the validation data
        val = ImageDataGenerator().flow_from_directory(directory='val', target_size=(img_size,img_size), batch_size=10000)
        #set the testing data
        test = ImageDataGenerator().flow_from_directory(directory='test', target_size=(img_size,img_size), batch_size=10000)
    
        #load train images data and labels
        imgs_train, labels_train = next(train)
        #load validation images data and labels
        imgs_val, labels_val = next(val)
        
        #show the images and their labels
        # self.plots(imgs_train, titles = labels_train)
    
        Alexnet_model = self.model
        #fit AlexNet model
        history_Alexnet = Alexnet_model.fit(imgs_train, 
                                           labels_train, 
                                           validation_data=(imgs_val, labels_val), 
                                           epochs=50)
        # save model
        Alexnet_model.save(save_path + "Alex.h5")
        
        #for plotting losses curve
        loss_training = history_Alexnet.history['loss']
        loss_test = history_Alexnet.history['val_loss']
    
        #for plotting accyracies curve
        accuracy_training = history_Alexnet.history['accuracy']
        accuracy_test = history_Alexnet.history['val_accuracy']
    
        loss_training = history_Alexnet.history['loss']
        loss_test = history_Alexnet.history['val_loss']
    
        accuracy_training = history_Alexnet.history['accuracy']
        accuracy_test = history_Alexnet.history['val_accuracy']
    
        #for Plotting
        plt.plot(loss_test)
        plt.plot(loss_training)
    
        #set the titles of losses plot
        plt.xlabel("# Of Epochs")
        plt.ylabel("Loss")
        plt.legend(['val Loss', 'Train Loss'])
        plt.show()
    
        #set the titles of accuracies plot
        plt.plot(accuracy_test)
        plt.plot(accuracy_training)
        plt.xlabel("# Of Epochs")
        plt.ylabel("Accuracy")
        plt.legend(['val accuracy', 'Train accuracy'])
        plt.show()
        

class MyVGG16():
    model = None
    model_trained = None
    
    def __init__(self):
        #build the VGG16 model
        img_size = 150
        vgg_model = VGG16(weights='imagenet',include_top=False, input_shape=(img_size,img_size,3),classes=25, pooling="avg")

        #make the layers trainable
        for layer in vgg_model.layers:
            layer.trainable = True

        #build the sequential model
        model_vgg = keras.models.Sequential()
        model_vgg.add(vgg_model)

        #add a flatten layer
        model_vgg.add(Flatten())

        #add dense layers
        model_vgg.add(Dense(128, activation='relu'))
        model_vgg.add(Dense(64, activation='relu'))

        #add softmax activation function to output layer
        model_vgg.add(Dense(25, activation='softmax'))

        #print the VGG16 model summary
        print(model_vgg.summary())

        #compile the VGG16 model 
        model_vgg.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
        
        self.model = model_vgg

    def train(self, data_path, save_path) -> None:
        # 进入数据目录
        os.chdir(data_path)
        model = self.model
        
        #set the image size to 150
        img_size = 150
        #set the training data
        train = ImageDataGenerator().flow_from_directory(directory='train', target_size=(img_size,img_size), batch_size=10000)
        #set the validation data
        val = ImageDataGenerator().flow_from_directory(directory='val', target_size=(img_size,img_size), batch_size=10000)
        #set the testing data
        test = ImageDataGenerator().flow_from_directory(directory='test', target_size=(img_size,img_size), batch_size=10000)
    
        #load train images data and labels
        imgs_train, labels_train = next(train)
        #load validation images data and labels
        imgs_val, labels_val = next(val)
    
        Alexnet_model = self.model
        
        # 拟合数据
        history_vgg= model.fit(imgs_train, labels_train, validation_data=(imgs_val, labels_val), epochs=50)
        
        # 保存模型
        model.save(save_path)

        #set the image size to 150
        img_size = 150
        #set the training data
        train = ImageDataGenerator().flow_from_directory(directory='train', target_size=(img_size,img_size), batch_size=10000)
        #set the validation data
        val = ImageDataGenerator().flow_from_directory(directory='val', target_size=(img_size,img_size), batch_size=10000)
        #set the testing data
        test = ImageDataGenerator().flow_from_directory(directory='test', target_size=(img_size,img_size), batch_size=10000)
    
        #load train images data and labels
        imgs_train, labels_train = next(train)
        #load validation images data and labels
        imgs_val, labels_val = next(val)
        
        #plot the losses curves
        loss_training = history_vgg.history['loss']
        loss_test = history_vgg.history['val_loss']

        #plot the accuracies curves
        accuracy_training = history_vgg.history['accuracy']
        accuracy_test = history_vgg.history['val_accuracy']

        loss_training = history_vgg.history['loss']
        loss_test = history_vgg.history['val_loss']

        accuracy_training = history_vgg.history['accuracy']
        accuracy_test = history_vgg.history['val_accuracy']

        #for Plotting
        plt.plot(loss_test)
        plt.plot(loss_training)

        #set the titles of the graph
        plt.xlabel("# Of Epochs")
        plt.ylabel("Loss")
        plt.legend(['val Loss', 'Train Loss'])
        plt.show()

        #set the titles of the graph
        plt.plot(accuracy_test)
        plt.plot(accuracy_training)
        plt.xlabel("# Of Epochs")
        plt.ylabel("Accuracy")
        plt.legend(['val accuracy', 'Train accuracy'])
        plt.show()
        
    def load_specify_model(self, model_filename):
        self.model_trained = tf.keras.models.load_model(model_filename)
        
    def predict(self, source_file :str) -> str:
        exec = Exec2img()
        path = exec.exec2img(source_file)
        z = plt.imread(path)
        plt.imshow(z)
    
        img = tf.keras.utils.load_img(path, target_size=(150, 150))
        x = tf.keras.utils.img_to_array(img)
        x = np.expand_dims(x, axis=0) 
        classes = self.model.predict(x)
        classes = np.argmax(classes)
    
        #set the images labels
        label = ['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.P', 'C2LOP.gen!g', 'Dialplatform.B', 'Dontovo.A', 'Fakerean', 'Instantaccess', 'Lolyda.AA1', 'Lolyda.AA2', 'Lolyda.AA3', 'Lolyda.AT', 'Malex.gen!J', 'Obfuscator.AD', 'Rbot!gen', 'Skintrim.N', 'Swizzor.gen!E', 'Swizzor.gen!I', 'VB.AT', 'Wintrim.BX', 'Yuner.A']
        return label[classes]
        
    def eval(self) -> str:
        pass